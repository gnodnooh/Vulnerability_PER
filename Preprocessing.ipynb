{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peru Survey Analyses\n",
    "This script analyze the survey responses obtained from Peru. More details will be updated later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon\n",
    "import rasterio\n",
    "\n",
    "# Global map and Peru District map\n",
    "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "country = world[['iso_a3','geometry']]\n",
    "country = country.set_index('iso_a3')\n",
    "peru = gpd.read_file('./data/DEPARTAMENTOS.shp')\n",
    "depart = peru[['DEPARTAMEN', 'geometry']]\n",
    "depart = depart.set_index('DEPARTAMEN')\n",
    "# Survey results (raw file from Hugh Roland)\n",
    "table = pd.read_csv('./data/peru.csv')\n",
    "variable = pd.read_excel('./data/survey_variables.xlsx').set_index('Name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Survey data cleaning\n",
    "- Define a work area of each respondent\n",
    "- Translate Spanish to English\n",
    "- Convert likert-scale to numeric\n",
    "- Exclude respondents who didn't answer the most of questions (>60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1: Which of the following best describes your work area (check all thatcorrespond)?\n",
    "colQ11 = 'Q3'\n",
    "table[colQ11] = table[colQ11].replace({'Salud pública':'Public health',\n",
    "                                     'Ámbito climático':'Climate scope',\n",
    "                                     'Ingeniería':'Engineering',\n",
    "                                     'Respuesta ante desastres':'Disaster response',\n",
    "                                     'Académica':'Academic',\n",
    "                                     'Otra (escriba):':'Other'})\n",
    "# - Others:\n",
    "colQ12 = 'Q3_6_TEXT'\n",
    "table[colQ12] = table[colQ12].replace({'Aviacion':'Aviation',\n",
    "                                       'Estudiante':'Student', \n",
    "                                       'Evaluación del peligro':'Hazard assessment',\n",
    "                                       'Gestión de riesgos de desastres y resiliencia climática':'Disaster risk management and climate resilience',\n",
    "                                       'Pronóstico meteorológico':'Meteorological forecast',\n",
    "                                       'TODAS ':'ALL', \n",
    "                                       'Turismo Sostenible':'Sustainable tourism',\n",
    "                                       'supervisiones forestales':'Forestry supervision'})\n",
    "# - What organization do you work for?\n",
    "# table.to_excel('./data/peru.xlsx')\n",
    "# - Based on the answers to Q1, we made a column of \"Work\", representing respondent's work area\n",
    "table = pd.read_excel('./data/peru_workarea.xlsx')\n",
    "\n",
    "# Q2: How would you rate the following areas of natural disaster PREPAREDNESS in Iquitos? \n",
    "colQ2 = ['Q11_1','Q11_2','Q11_3','Q11_4','Q11_5','Q11_6','Q11_7','Q11_8',\n",
    "        'Q11_9','Q11_10','Q11_11','Q11_12','Q11_13','Q11_14','Q11_15']\n",
    "table[colQ2] = table[colQ2].replace({'Muy buena':4,             # Very good (4)\n",
    "                                     'Buena':3,                 # Good (3)\n",
    "                                     'Aceptable':2,             # Acceptable (2)\n",
    "                                     'Deficiente':1,            # Poor (1)\n",
    "                                     'Muy deficiente':0})       # Very poor (0)\n",
    "\n",
    "# Q3: How much do you agree or disagree with each statement?\n",
    "colQ3 = ['Q12_1','Q12_2','Q12_3','Q12_4','Q12_5']\n",
    "table[colQ3] = table[colQ3].replace({'Muy de acuerdo':4,                  # Strongly agree (4)\n",
    "                                     'Levemente de acuerdo':3,            # Slightly agree (3)\n",
    "                                     'Ni de acuerdo ni en desacuerdo':2,  # Neither agree nor disagree (2)\n",
    "                                     'Levemente en desacuerdo':1,         # Disagree somewhat (1)\n",
    "                                     'Muy en desacuerdo':0})              # Disagree strongly (0)\n",
    "\n",
    "# Q4: How effective do you think the communication surrounding natural disaster response/preparedness is among... \n",
    "colQ4 = ['Q13_1','Q13_2','Q13_3','Q13_4']\n",
    "table[colQ4] = table[colQ4].replace({'Extremadamente eficaz':4,           # Extremely effective (4)\n",
    "                                     'Muy eficaz':3,                      # Very effective (3)\n",
    "                                     'Moderadamente eficaz':2,            # Moderately effective (2)\n",
    "                                     'Levemente eficaz':1,                # Slightly effective (1)\n",
    "                                     'No es eficaz en absoluto':0})       # Not at all effective (0)\n",
    "\n",
    "# Q51: In your opinion, how risky do people in Iquitos think floods are for their community?!\n",
    "colQ51 = 'Q39'\n",
    "table[colQ51] = table[colQ51].replace({'Extremadamente riesgosas':4,      # Extremely risky (4)\n",
    "                                       'Muy riesgosas':3,                 # Very risky (3)\n",
    "                                       'Moderadamente riesgosas':2,       # Moderately risky (2)\n",
    "                                       'Ligeramente riesgosas':1,         # Slightly risky (1)\n",
    "                                       'Nada riesgosas':0})               # Not at all risky (0)\n",
    "\n",
    "# Q52: In your opinion, how responsive are people in Iquitos to warnings about forecasted floods?!\n",
    "colQ52 = 'Q40'\n",
    "table[colQ52] = table[colQ52].replace({'Extremadamente receptivas':4,     # Extremely responsive (4)\n",
    "                                       'Muy receptivas':3,                # Very responsive (3)\n",
    "                                       'Moderadamente receptivas':2,      # Moderately responsive (2)\n",
    "                                       'Ligeramente receptivas':1,        # Slightly responsive (1)\n",
    "                                       'Nada receptivas':0})              # Not at all responsive (0)\n",
    "\n",
    "# Q6: To what extent does disaster aid decision-making in Iquitos consider: \n",
    "colQ6 = ['Q20_1','Q20_2']\n",
    "table[colQ6] = table[colQ6].replace({'Lo considera siempre':4,            # Extremely considered (4)\n",
    "                                     'Lo considera mucho':3,              # Very considered (3)\n",
    "                                     'Lo considera moderadamente':2,      # Moderately considered (2)\n",
    "                                     'Lo considera ligeramente':1,        # Slightly considered (1)\n",
    "                                     'No lo considera en absoluto':0})    # Not at all considered (0)\n",
    "\n",
    "# Q7: What flood impacts concern you most?\n",
    "colQ7 = ['Q23_1','Q23_2','Q23_3','Q23_4','Q23_5','Q23_6','Q23_7']\n",
    "table[colQ7] = table[colQ7].replace({'Me preocupan extremadamente':4,     # Extremely concerned (4)\n",
    "                                     'Me preocupan mucho':3,              # Very concerned (3)\n",
    "                                     'Me preocupan moderadamente':2,      # Moderately concerned (2)\n",
    "                                     'Me preocupan ligeramente':1,        # Slightly concerned (1)\n",
    "                                     'No me preocupan para nada':0})      # Not at all concerned (0)\n",
    "\n",
    "# Q8: Which of the following specific indicators are important in determining flood-related social vulnerability in Peru? \n",
    "colQ8 = ['Q25_1','Q25_2','Q25_3','Q25_4','Q25_5','Q25_6',\n",
    "        'Q28_1','Q28_2','Q28_3','Q28_4','Q28_5',\n",
    "        'Q30_1','Q30_2','Q30_3','Q30_4','Q30_5',\n",
    "        'Q31_1','Q31_2','Q31_3','Q31_4','Q31_5','Q31_6',\n",
    "        'Q32_1','Q32_2','Q32_3']\n",
    "table[colQ8] = table[colQ8].replace({'Extremadamente importante':4,       # Extremely important (4)\n",
    "                                     'Muy importante':3,                  # Very important (3)\n",
    "                                     'Moderadamente importante':2,        # Moderately important (2)\n",
    "                                     'Ligeramente importante':1,          # Slightly important (1)\n",
    "                                     'Nada importante':0})                # Not at all important (0)\n",
    "\n",
    "# Q9: How influential are the following factors in DETERMINING or CREATING vulnerability in flood-prone regions in Peru? \n",
    "colQ9 = ['Q36_1','Q36_2','Q36_3','Q36_4','Q36_5','Q36_6','Q36_7','Q36_8']\n",
    "table[colQ9] = table[colQ9].replace({'Extremadamente influyente':4,       # Extremely influential (4)\n",
    "                                     'Muy influyente':3,                  # Very influential (3)\n",
    "                                     'Moderadamente influyente':2,        # Moderately influential (2)\n",
    "                                     'Ligeramente influyente':1,          # Slightly influential (1)\n",
    "                                     'Para nada influyente':0})           # Not at all influential (0)\n",
    "\n",
    "# Q10: What makes an assessment of flood-related vulnerability useful?\n",
    "colQ10 = ['Q38_1','Q38_2','Q38_3','Q38_4','Q38_5','Q38_6']\n",
    "table[colQ10] = table[colQ10].replace({'Extremadamente importante':4,     # Extremely important (4)\n",
    "                                       'Muy importante':3,                # Very important (3)  \n",
    "                                       'Moderadamente importante':2,      # Moderately important (2)\n",
    "                                       'Ligeramente importante':1,        # Slightly important (1)\n",
    "                                       'Poco importante':0})              # Not at all important (0)\n",
    "\n",
    "# Retain respondents who answers more than 60 questions\n",
    "colALL = colQ2+colQ3+colQ4+[colQ51,colQ52]+colQ6+colQ7+colQ8+colQ9+colQ10   # Total 74 answers except Q37\n",
    "retain = table[colALL].isna().sum(axis=1) < 60\n",
    "table = table[retain]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find locations (country, department) of respondents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the corresponding country and district of the respondent\n",
    "resp = table[['LocationLatitude','LocationLongitude']]\n",
    "resp.columns = ['lat', 'lon']\n",
    "resp = resp.assign(country='')\n",
    "resp = resp.assign(depart='')\n",
    "# Source: https://stackoverflow.com/a/48105955/10164193\n",
    "for index, row in resp.iterrows():\n",
    "    pt = Point(row['lon'], row['lat'])\n",
    "    if pt.is_valid:\n",
    "        temp = [pt.within(geom['geometry']) for key, geom in country.iterrows()]\n",
    "        resp.loc[index,'country'] = country.index[np.array(temp)]\n",
    "    if resp.loc[index,'country'] == 'PER':\n",
    "        temp = [pt.within(geom['geometry']) for key, geom in depart.iterrows()]\n",
    "        resp.loc[index,'depart'] = depart.index[np.array(temp)]\n",
    "    else:\n",
    "        resp.loc[index,'depart'] = resp.loc[index,'country']\n",
    "\n",
    "# Saved the results        \n",
    "# TODO: MERGE DATAFRAME AND SAVE\n",
    "table = table.merge(resp[['country','depart']], left_index=True, right_index=True)\n",
    "table.to_csv('./data/peru_modified.csv')\n",
    "resp_valid = resp[~resp['lat'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'resp_valid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-fced9da62cc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# order = resp_valid['depart'].value_counts().index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0morder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'LIMA'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'LORETO'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'JUNIN'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'UCAYALI'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'USA'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'MEX'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcountplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp_valid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'depart'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp_valid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'depart'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'resp_valid' is not defined"
     ]
    }
   ],
   "source": [
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "fig = plt.figure(figsize=(7,5))\n",
    "sns.set(style=\"darkgrid\", font_scale=1.3)\n",
    "# order = resp_valid['depart'].value_counts().index\n",
    "order = ['LIMA','LORETO','JUNIN','UCAYALI','USA','MEX']\n",
    "ax = sns.countplot(resp_valid['depart'], order=order)\n",
    "plt.ylim([0, resp_valid['depart'].value_counts().max()+2])\n",
    "plt.xlabel('')\n",
    "plt.ylabel('Count')\n",
    "# Show numbers at the top of the patches\n",
    "for p in ax.patches:\n",
    "        ax.annotate('{}'.format(p.get_height()), (p.get_x()+0.4, p.get_height()+0.5), \n",
    "                    ha='center',color='blue')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# Save a figure\n",
    "if True:\n",
    "    fn_save = './figures/location.png'\n",
    "    fig.savefig(fn_save, bbox_inches='tight')\n",
    "    print('%s is saved.' % fn_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(table[colALL].isna().sum(axis=1) < 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(colALL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Significance Tests\n",
    "From [USDA](https://www.joe.org/joe/2011october/tt7.php)<br>\n",
    "The hypothesis being tested by the Mann-Whitney U test is, \"Do two independent samples represent two populations with different median values?\" (Sheskin, 2000, p. 289). In our case, the hypothesis can be re-phrased as \"Does the median rank of Likert scores (scores that vary from 1 to 5) differ between males and females? Once the concept behind using the Mann-Whitney U test is grasped, it becomes an easy matter to use this procedure to test for correlations in survey responses associated with any pair of survey questions, provided that the responses are categorical or can be sorted into categories.\n",
    "\n",
    "In some cases, it is more convenient to divide the respondents into three or more groups before carrying out a rank-sum test on the response variable. For this situation, the Kruskal-Wallis test is the appropriate test to apply. It uses essentially the same procedures as the Mann-Whitney U test, except that rank-sums are computed for three or more groups instead of for two. As you might expect, JOE authors are already using these techniques to analyze Likert scale responses (e.g., Nichols, 2004; O'Neill & Xiao, 2006), although details of the statistical methods employed are seldom provided.\n",
    "\n",
    "From [Wiki](https://en.wikipedia.org/wiki/Likert_scale)<br>\n",
    "To model binary Likert responses directly, they may be represented in a binomial form by summing agree and disagree responses separately. The chi-squared, Cochran's Q test, or McNemar test are common statistical procedures used after this transformation. Non-parametric tests such as chi-squared test, Mann–Whitney test, Wilcoxon signed-rank test, or Kruskal–Wallis test.[17] are often used in the analysis of Likert scale data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'StartDate', 'EndDate', 'Status', 'IPAddress', 'Progress',\n",
       "       'Duration (in seconds)', 'Finished', 'RecordedDate', 'ResponseId',\n",
       "       ...\n",
       "       'Q38_2', 'Q38_3', 'Q38_4', 'Q38_5', 'Q38_6', 'Q16', 'Q17', 'Q41',\n",
       "       'country', 'depart'],\n",
       "      dtype='object', length=103)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "# stats.mannwhitneyu(Pooh.Likert, Piglet.Likert)\n",
    "\n",
    "table.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics=1922.000, p=0.011\n",
      "Different distribution (reject H0)\n"
     ]
    }
   ],
   "source": [
    "# Mann-Whitney U test\n",
    "from numpy.random import seed\n",
    "from numpy.random import randn\n",
    "from scipy.stats import mannwhitneyu\n",
    "# seed the random number generator\n",
    "seed(1)\n",
    "# generate two independent samples\n",
    "data1 = 5 * randn(50) + 50\n",
    "data2 = 5 * randn(100) + 51\n",
    "# compare samples\n",
    "stat, p = mannwhitneyu(data1, data2)\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "# interpret\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "\tprint('Same distribution (fail to reject H0)')\n",
    "else:\n",
    "\tprint('Different distribution (reject H0)')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([58.12172682, 46.94121793, 47.35914124, 44.63515689, 54.32703815,\n",
       "       38.49230652, 58.72405882, 46.1939655 , 51.59519548, 48.75314812,\n",
       "       57.31053969, 39.69929645, 48.38791398, 48.07972823, 55.66884721,\n",
       "       44.50054366, 49.13785896, 45.61070791, 50.21106873, 52.91407607,\n",
       "       44.49690411, 55.72361855, 54.5079536 , 52.51247169, 54.50427975,\n",
       "       46.5813607 , 49.38554887, 45.32115283, 48.6605596 , 52.65177733,\n",
       "       46.54169624, 48.01623237, 46.5641365 , 45.77397179, 46.64376935,\n",
       "       49.93667701, 44.41344826, 51.17207849, 58.29901089, 53.7102208 ,\n",
       "       49.04082224, 45.56185518, 46.26420853, 58.46227301, 50.25403877,\n",
       "       46.81502177, 50.95457742, 60.50127568, 50.60079476, 53.08601555])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
